---
---
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="Machine Learning, R Programming, Statistics, Artificial Intelligence">
    <meta name="author" content="Manuel Amunategui">
    <link rel="icon" href="../favicon.ico">

    <title>Data Exploration & Machine Learning, Hands-on</title>

    {% include externals.html %}
  
</head>

<body>

<main role="main">

{% include header.html %}
   
{% include signup.html %}

<div class="container">
  <div class="blog-header">
    <h1 class="blog-title">The Sparse Matrix and {glmnet}</h1>
    <p class="lead blog-description">Practical walkthroughs on machine learning, data exploration and finding insight.</p>
  </div>
   
 <p><strong>Resources</strong></p>
<ul>
<li type="square"><a href="https://www.youtube.com/watch?v=Ysh2gs8VKvQ&amp;list=UUq4pm1i_VZqxKVVOz5qRBIA" target="_blank">YouTube Companion Video</a></li>
<li type="square"><a href="#sourcecode">Full Source Code</a></li>
</ul>
<p><br />
<strong>Packages Used in this Walkthrough</strong></p>

<ul>
        <li type="square"><b>{Matrix}</b> - creates sparse/dense matrices</li>
        <li type="square"><b>{glmnet}</b> - generalized linear models</li>
        <li type="square"><b>{pROC}</b> - ROC tools</li>
</ul>

<p><br /><br />
In this walkthough, I am going to show how sparse matrices work in R and how to use them with the GLMNET package.</p>

<p>For those that aren’t familiar with sparse matrices, or the sparse matrix, as the name implies, it is a large but ideally hollow data set. If your data contains lots of zeros then a sparse matrix is a very memory-efficient way of holding that data. For example, if you have a lot of dummy variables, most of that data will be zeros, and a sparse matrix will only hold non-zero data and ignore the zeros, thus using a lot less memory and allowing the memorization of much larger data sets than traditional data frames.</p>

<p><strong>Wikipedia</strong> has great write-up on the <a href="http://en.wikipedia.org/wiki/Sparse_matrix" target="-blank">sparse matrix and related theories</a> if you want to dive into this in more details.</p>

<p>Unfortunately the sparse matrix in R doesn’t accept <strong>NAs</strong>, <strong>NaNs</strong> and <strong>Infinites</strong>… Also, normalization functions, such as centering or scaling, could affect the zero values and render the data set into a non-sparse matrix and defeating any memory-efficient advantages.</p>

<p>Let’s start with a simple data set called <code class="highlighter-rouge">some_dataframe</code>:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">print</span><span class="p">(</span><span class="n">some_dataframe</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>##    c1 c2 c3 c4 c5 c6 c7 c8 c9 c10 outcome
## 1   2  7  0  0  0  0  0  0  0   0       0
## 2   0  0  3  0  0  0  0  0  0   0       0
## 3   0  0  0  6  1  0  0  0  0   0       0
## 4   0  0  0  2  0  0  0  0  0   0       0
## 5   0  0  0  0  0  0  0  0 12   0       1
## 6   0  0  0  0  0 25  0  0  0   0       1
## 7   1  0  0  0  2  0  0  0  0   0       0
## 8   0  0  0  2  0  0  0  0  0   0       0
## 9   0  0  0  0  0  0  0  0 14   0       1
## 10  0  0  0  0  0 21  0  0  0   0       1
## 11  0  0  0  0  0  0 28  0  0   0       1
## 12  0  0  0  0  0  0  0 35  0   0       1
## 13  0  0  0  0  0  0  0  0 42   0       1
## 14  0  0  0  0  0  0  0  0  0  49       1
</code></pre>
</div>
<p>To see the above <strong>data.frame</strong> in a <strong>matrix</strong> format simply requires casting it to a matrix:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">some_matrix</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.matrix</span><span class="p">(</span><span class="n">some_dataframe</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">10</span><span class="p">])</span><span class="w">
</span><span class="n">print</span><span class="p">(</span><span class="n">some_matrix</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>##       c1 c2 c3 c4 c5 c6 c7 c8 c9 c10
##  [1,]  2  7  0  0  0  0  0  0  0   0
##  [2,]  0  0  3  0  0  0  0  0  0   0
##  [3,]  0  0  0  6  1  0  0  0  0   0
##  [4,]  0  0  0  2  0  0  0  0  0   0
##  [5,]  0  0  0  0  0  0  0  0 12   0
##  [6,]  0  0  0  0  0 25  0  0  0   0
##  [7,]  1  0  0  0  2  0  0  0  0   0
##  [8,]  0  0  0  2  0  0  0  0  0   0
##  [9,]  0  0  0  0  0  0  0  0 14   0
## [10,]  0  0  0  0  0 21  0  0  0   0
## [11,]  0  0  0  0  0  0 28  0  0   0
## [12,]  0  0  0  0  0  0  0 35  0   0
## [13,]  0  0  0  0  0  0  0  0 42   0
## [14,]  0  0  0  0  0  0  0  0  0  49
</code></pre>
</div>

<p>Visually, it isn’t much different than the data frame (internally, a matrix is restricted to one data type only). In order to transform it into a sparse matrix, we load the <strong>Matrix library</strong>, call the <code class="highlighter-rouge">Matrix</code> function with the <code class="highlighter-rouge">sparse</code> flag set to true:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">Matrix</span><span class="p">)</span><span class="w">
</span><span class="n">print</span><span class="p">(</span><span class="n">Matrix</span><span class="p">(</span><span class="n">some_matrix</span><span class="p">,</span><span class="w"> </span><span class="n">sparse</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">))</span><span class="w">
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>## 14 x 10 sparse Matrix of class "dgCMatrix"
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>##    [[ suppressing 10 column names 'c1', 'c2', 'c3' ... ]]
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>##                               
##  [1,] 2 7 . . .  .  .  .  .  .
##  [2,] . . 3 . .  .  .  .  .  .
##  [3,] . . . 6 1  .  .  .  .  .
##  [4,] . . . 2 .  .  .  .  .  .
##  [5,] . . . . .  .  .  . 12  .
##  [6,] . . . . . 25  .  .  .  .
##  [7,] 1 . . . 2  .  .  .  .  .
##  [8,] . . . 2 .  .  .  .  .  .
##  [9,] . . . . .  .  .  . 14  .
## [10,] . . . . . 21  .  .  .  .
## [11,] . . . . .  . 28  .  .  .
## [12,] . . . . .  .  . 35  .  .
## [13,] . . . . .  .  .  . 42  .
## [14,] . . . . .  .  .  .  . 49
</code></pre>
</div>
<p>And here we finally get a sense of its efficiency, it only retains the non-zero values!</p>
{% include follow-me.html %}
<p><strong>GLMNET package</strong><br />
The help files describes the <code class="highlighter-rouge">GLMNET</code> package as a package containing ‘extremely efficient procedures for fitting lasso or elastic-net regularization for linear regression, logistic and multinomial regression models, poisson regression and the Cox model and more (<a href="http://cran.r-project.org/web/packages/glmnet/index.html" target="_blank">from the help files</a>).</p>

<p>Unfortunately in R, few models support sparse matrices besides <strong>GLMNET</strong> (that I know of) therefore in conversations about modeling with R, when the subject of sparse matrices comes up, it is usually followed by the <code class="highlighter-rouge">glmnet</code> model.</p>

<p>Let’s start by splitting our <code class="highlighter-rouge">some_dataframe</code> in two parts: a 2/3 portion that will become our training data set and a 1/3 portion for our testing data set (always set the <code class="highlighter-rouge">seed</code> so random draws are reproducible):</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">set.seed</span><span class="p">(</span><span class="m">2</span><span class="p">)</span><span class="w">
</span><span class="n">split</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="n">nrow</span><span class="p">(</span><span class="n">some_dataframe</span><span class="p">),</span><span class="w"> </span><span class="nf">floor</span><span class="p">(</span><span class="m">0.7</span><span class="o">*</span><span class="n">nrow</span><span class="p">(</span><span class="n">some_dataframe</span><span class="p">)))</span><span class="w">
</span><span class="n">train</span><span class="w"> </span><span class="o">&lt;-</span><span class="n">some_dataframe</span><span class="p">[</span><span class="n">split</span><span class="p">,]</span><span class="w">
</span><span class="n">test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">some_dataframe</span><span class="p">[</span><span class="o">-</span><span class="n">split</span><span class="p">,]</span><span class="w">
</span></code></pre>
</div>

<p>We then construct a sparse model matrix using the typical <strong>R</strong> formula:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">glmnet</span><span class="p">)</span><span class="w"> 
</span><span class="n">train_sparse</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sparse.model.matrix</span><span class="p">(</span><span class="o">~</span><span class="n">.</span><span class="p">,</span><span class="n">train</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">10</span><span class="p">])</span><span class="w">
</span><span class="n">test_sparse</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sparse.model.matrix</span><span class="p">(</span><span class="o">~</span><span class="n">.</span><span class="p">,</span><span class="n">test</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">10</span><span class="p">])</span><span class="w">
</span><span class="n">print</span><span class="p">(</span><span class="n">train_sparse</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>## 9 x 11 sparse Matrix of class "dgCMatrix"
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>##    [[ suppressing 11 column names '(Intercept)', 'c1', 'c2' ... ]]
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>##                             
## 3  1 . . . 6 1  .  . .  .  .
## 10 1 . . . . . 21  . .  .  .
## 7  1 1 . . . 2  .  . .  .  .
## 2  1 . . 3 . .  .  . .  .  .
## 13 1 . . . . .  .  . . 42  .
## 9  1 . . . . .  .  . . 14  .
## 11 1 . . . . .  . 28 .  .  .
## 6  1 . . . . . 25  . .  .  .
## 14 1 . . . . .  .  . .  . 49
</code></pre>
</div>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">print</span><span class="p">(</span><span class="n">test_sparse</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>## 5 x 11 sparse Matrix of class "dgCMatrix"
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>##    [[ suppressing 11 column names '(Intercept)', 'c1', 'c2' ... ]]
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>##                           
## 1  1 2 7 . . . . .  .  . .
## 4  1 . . . 2 . . .  .  . .
## 5  1 . . . . . . .  . 12 .
## 8  1 . . . 2 . . .  .  . .
## 12 1 . . . . . . . 35  . .
</code></pre>
</div>

<p>We call the <code class="highlighter-rouge">glmnet</code> model and get our fit:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">fit</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">glmnet</span><span class="p">(</span><span class="n">train_sparse</span><span class="p">,</span><span class="n">train</span><span class="p">[,</span><span class="m">11</span><span class="p">])</span><span class="w">
</span></code></pre>
</div>

<p>And call the <code class="highlighter-rouge">predict</code> function to get our probabilities:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">pred</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="n">test_sparse</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="o">=</span><span class="s2">"class"</span><span class="p">)</span><span class="w">
</span><span class="n">print</span><span class="p">(</span><span class="n">head</span><span class="p">(</span><span class="n">pred</span><span class="p">[,</span><span class="m">1</span><span class="o">:</span><span class="m">5</span><span class="p">]))</span><span class="w">
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>##        s0     s1     s2     s3    s4
## 1  0.6667 0.6742 0.6815 0.6884 0.695
## 4  0.6667 0.6742 0.6815 0.6884 0.695
## 5  0.6667 0.6742 0.6815 0.6884 0.695
## 8  0.6667 0.6742 0.6815 0.6884 0.695
## 12 0.6667 0.6742 0.6815 0.6884 0.695
</code></pre>
</div>

<p>The reason it returns many probability sets is because <code class="highlighter-rouge">glmnet</code> fits the model for different regularization parameters at the same time. To help us choose the best prediction set, we can use the function <code class="highlighter-rouge">cv.glmnet</code>. This will use cross validation to find the fit with the smallest error. Let’s call cv.glmnet and pass the results to the <code class="highlighter-rouge">s</code> paramter (the prenalty parameter) of the <code class="highlighter-rouge">predict</code> function:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="c1"># use cv.glmnet to find best lambda/penalty - choosing small nfolds for cv due to… 
# s is the penalty parameter
</span><span class="n">cv</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cv.glmnet</span><span class="p">(</span><span class="n">train_sparse</span><span class="p">,</span><span class="n">train</span><span class="p">[,</span><span class="m">11</span><span class="p">],</span><span class="n">nfolds</span><span class="o">=</span><span class="m">3</span><span class="p">)</span><span class="w">
</span><span class="n">pred</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="n">test_sparse</span><span class="p">,</span><span class="n">type</span><span class="o">=</span><span class="s2">"response"</span><span class="p">,</span><span class="w"> </span><span class="n">s</span><span class="o">=</span><span class="n">cv</span><span class="o">$</span><span class="n">lambda.min</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<p><strong>NOTE</strong>: the <code class="highlighter-rouge">cv.glmnet</code> returns various values that may be important for your modeling needs. In particular <code class="highlighter-rouge">lambda.min</code> and <code class="highlighter-rouge">lambda.1se</code>. One is the smallest error and the other is the simplest error. Refer to the help files to find the best one for your needs.</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">print</span><span class="p">(</span><span class="nf">names</span><span class="p">(</span><span class="n">cv</span><span class="p">))</span><span class="w">
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>##  [1] "lambda"     "cvm"        "cvsd"       "cvup"       "cvlo"      
##  [6] "nzero"      "name"       "glmnet.fit" "lambda.min" "lambda.1se"
</code></pre>
</div>

<p>As the data is made up, let’s not read too deeply into these predictions:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">print</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>##         1
## 1  0.9898
## 4  0.8306
## 5  0.9898
## 8  0.8306
## 12 0.9898
</code></pre>
</div>

<p>Let’s see how the <code class="highlighter-rouge">sparse.model.matrix</code> function of the <strong>Matrix</strong> package handles discreet values. I added a factor variable <code class="highlighter-rouge">mood</code> with two levels: <code class="highlighter-rouge">happy</code> and <code class="highlighter-rouge">sad</code>:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">print</span><span class="p">(</span><span class="n">cat_dataframe</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>##    c1 c2 c3 c4 c5 c6 c7 c8 c9 c10  mood outcome
## 1   2  7  0  0  0  0  0  0  0   0 happy       0
## 2   0  0  3  0  0  0  0  0  0   0 happy       0
## 3   0  0  0  6  1  0  0  0  0   0 happy       0
## 4   0  0  0  2  0  0  0  0  0   0 happy       0
## 5   0  0  0  0  0  0  0  0 12   0   sad       1
## 6   0  0  0  0  0 25  0  0  0   0   sad       1
## 7   1  0  0  0  2  0  0  0  0   0 happy       0
## 8   0  0  0  2  0  0  0  0  0   0 happy       0
## 9   0  0  0  0  0  0  0  0 14   0   sad       1
## 10  0  0  0  0  0 21  0  0  0   0   sad       1
## 11  0  0  0  0  0  0 28  0  0   0   sad       1
## 12  0  0  0  0  0  0  0 35  0   0   sad       1
## 13  0  0  0  0  0  0  0  0 42   0   sad       1
## 14  0  0  0  0  0  0  0  0  0  49   sad       1
</code></pre>
</div>
<p>We call the <code class="highlighter-rouge">sparse.model.matrix</code> function and we notice that it turned <code class="highlighter-rouge">happy</code> into 0’s and <code class="highlighter-rouge">sad</code> into 1’s. Thus, we only see the 1’s:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">sparse.model.matrix</span><span class="p">(</span><span class="o">~</span><span class="n">.</span><span class="p">,</span><span class="n">cat_dataframe</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>## 14 x 13 sparse Matrix of class "dgCMatrix"
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>##    [[ suppressing 13 column names '(Intercept)', 'c1', 'c2' ... ]]
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>##                                  
## 1  1 2 7 . . .  .  .  .  .  . . .
## 2  1 . . 3 . .  .  .  .  .  . . .
## 3  1 . . . 6 1  .  .  .  .  . . .
## 4  1 . . . 2 .  .  .  .  .  . . .
## 5  1 . . . . .  .  .  . 12  . 1 1
## 6  1 . . . . . 25  .  .  .  . 1 1
## 7  1 1 . . . 2  .  .  .  .  . . .
## 8  1 . . . 2 .  .  .  .  .  . . .
## 9  1 . . . . .  .  .  . 14  . 1 1
## 10 1 . . . . . 21  .  .  .  . 1 1
## 11 1 . . . . .  . 28  .  .  . 1 1
## 12 1 . . . . .  .  . 35  .  . 1 1
## 13 1 . . . . .  .  .  . 42  . 1 1
## 14 1 . . . . .  .  .  .  . 49 1 1
</code></pre>
</div>
<p>Let’s complicate things by adding a few more levels to our factor:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">print</span><span class="p">(</span><span class="n">cat_dataframe</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>##    c1 c2 c3 c4 c5 c6 c7 c8 c9 c10    mood outcome
## 1   2  7  0  0  0  0  0  0  0   0   angry       0
## 2   0  0  3  0  0  0  0  0  0   0 neutral       0
## 3   0  0  0  6  1  0  0  0  0   0   happy       0
## 4   0  0  0  2  0  0  0  0  0   0   happy       0
## 5   0  0  0  0  0  0  0  0 12   0     sad       1
## 6   0  0  0  0  0 25  0  0  0   0     sad       1
## 7   1  0  0  0  2  0  0  0  0   0   happy       0
## 8   0  0  0  2  0  0  0  0  0   0   happy       0
## 9   0  0  0  0  0  0  0  0 14   0     sad       1
## 10  0  0  0  0  0 21  0  0  0   0 neutral       1
## 11  0  0  0  0  0  0 28  0  0   0     sad       1
## 12  0  0  0  0  0  0  0 35  0   0     sad       1
## 13  0  0  0  0  0  0  0  0 42   0     sad       1
## 14  0  0  0  0  0  0  0  0  0  49     sad       1
</code></pre>
</div>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">print</span><span class="p">(</span><span class="n">levels</span><span class="p">(</span><span class="n">cat_dataframe</span><span class="o">$</span><span class="n">mood</span><span class="p">))</span><span class="w">
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>## [1] "angry"   "happy"   "neutral" "sad"
</code></pre>
</div>
<p>We can compare the dimensions of both data sets:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="nf">dim</span><span class="p">(</span><span class="n">cat_dataframe</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>## [1] 14 12
</code></pre>
</div>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="nf">dim</span><span class="p">(</span><span class="n">sparse.model.matrix</span><span class="p">(</span><span class="o">~</span><span class="n">.</span><span class="p">,</span><span class="n">cat_dataframe</span><span class="p">))</span><span class="w">
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>## [1] 14 15
</code></pre>
</div>
<p>The sparse model has 3 extra columns. It broke out the 4 levels into 3. This is because it applied <code class="highlighter-rouge">Full Rank</code> to the set - you’re either one of the 3 moods, if you’re neither of the 3, then you’re assumed to be the 4th or <code class="highlighter-rouge">angry</code>. Check out <a href="http://amunategui.github.io/dummyVar-Walkthrough/" target="_blank">my walkthrough on dummy variables for more details</a>:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">print</span><span class="p">(</span><span class="n">sparse.model.matrix</span><span class="p">(</span><span class="o">~</span><span class="n">.</span><span class="p">,</span><span class="n">cat_dataframe</span><span class="p">))</span><span class="w">
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>## 14 x 15 sparse Matrix of class "dgCMatrix"
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>##    [[ suppressing 15 column names '(Intercept)', 'c1', 'c2' ... ]]
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>##                                      
## 1  1 2 7 . . .  .  .  .  .  . . . . .
## 2  1 . . 3 . .  .  .  .  .  . . 1 . .
## 3  1 . . . 6 1  .  .  .  .  . 1 . . .
## 4  1 . . . 2 .  .  .  .  .  . 1 . . .
## 5  1 . . . . .  .  .  . 12  . . . 1 1
## 6  1 . . . . . 25  .  .  .  . . . 1 1
## 7  1 1 . . . 2  .  .  .  .  . 1 . . .
## 8  1 . . . 2 .  .  .  .  .  . 1 . . .
## 9  1 . . . . .  .  .  . 14  . . . 1 1
## 10 1 . . . . . 21  .  .  .  . . 1 . 1
## 11 1 . . . . .  . 28  .  .  . . . 1 1
## 12 1 . . . . .  .  . 35  .  . . . 1 1
## 13 1 . . . . .  .  .  . 42  . . . 1 1
## 14 1 . . . . .  .  .  .  . 49 . . 1 1
</code></pre>
</div>
<p><br /><br /></p>

<p><a id="sourcecode">Full source code (<a href="https://github.com/amunategui/Sparse-Matrices-And-GLMNET-Demo" target="_blank">also on GitHub</a>)</a>:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="w">
</span><span class="n">some_dataframe</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read.table</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s2">"c1        c2     c3     c4     c5     c6     c7     c8     c9     c10     outcome
2     7     0     0     0     0     0     0     0     0     0
0     0     3     0     0     0     0     0     0     0     0
0     0     0     6     1     0     0     0     0     0     0
0     0     0     2     0     0     0     0     0     0     0
0     0     0     0     0     0     0     0     12     0     1
0     0     0     0     0     25     0     0     0     0     1
1     0     0     0     2     0     0     0     0     0     0
0     0     0     2     0     0     0     0     0     0     0
0     0     0     0     0     0     0     0     14     0     1
0     0     0     0     0     21     0     0     0     0     1
0     0     0     0     0     0     28     0     0     0     1
0     0     0     0     0     0     0     35     0     0     1
0     0     0     0     0     0     0     0     42     0     1
0     0     0     0     0     0     0     0     0     49     1"</span><span class="p">,</span><span class="w"> </span><span class="n">header</span><span class="o">=</span><span class="nb">T</span><span class="p">,</span><span class="w"> </span><span class="n">sep</span><span class="o">=</span><span class="s2">""</span><span class="p">)</span><span class="w"> 

</span><span class="n">library</span><span class="p">(</span><span class="n">Matrix</span><span class="p">)</span><span class="w">
</span><span class="n">some_matrix</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.matrix</span><span class="p">(</span><span class="n">some_dataframe</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">10</span><span class="p">])</span><span class="w">

</span><span class="c1"># show matrix representation of data set
</span><span class="n">Matrix</span><span class="p">(</span><span class="n">some_matrix</span><span class="p">,</span><span class="w"> </span><span class="n">sparse</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span><span class="w">

</span><span class="c1"># split data set into a train and test portion
</span><span class="n">set.seed</span><span class="p">(</span><span class="m">2</span><span class="p">)</span><span class="w">
</span><span class="n">split</span><span class="w"> </span><span class="o">&llt;-</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="n">nrow</span><span class="p">(</span><span class="n">some_dataframe</span><span class="p">),</span><span class="w"> </span><span class="nf">floor</span><span class="p">(</span><span class="m">0.7</span><span class="o">*</span><span class="n">nrow</span><span class="p">(</span><span class="n">some_dataframe</span><span class="p">)))</span><span class="w">
</span><span class="n">train</span><span class="w"> </span><span class="o">&lt;-</span><span class="n">some_dataframe</span><span class="p">[</span><span class="n">split</span><span class="p">,]</span><span class="w">
</span><span class="n">test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">some_dataframe</span><span class="p">[</span><span class="o">-</span><span class="n">split</span><span class="p">,]</span><span class="w">

</span><span class="c1"># transform both sets into sparse matrices using the sparse.model.matrix
</span><span class="n">train_sparse</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sparse.model.matrix</span><span class="p">(</span><span class="o">~</span><span class="n">.</span><span class="p">,</span><span class="n">train</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">10</span><span class="p">])</span><span class="w">
</span><span class="n">test_sparse</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sparse.model.matrix</span><span class="p">(</span><span class="o">~</span><span class="n">.</span><span class="p">,</span><span class="n">test</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">10</span><span class="p">])</span><span class="w">

</span><span class="c1"># model the sparse sets using glmnet
</span><span class="n">library</span><span class="p">(</span><span class="n">glmnet</span><span class="p">)</span><span class="w">  
</span><span class="n">fit</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">glmnet</span><span class="p">(</span><span class="n">train_sparse</span><span class="p">,</span><span class="n">train</span><span class="p">[,</span><span class="m">11</span><span class="p">])</span><span class="w">

</span><span class="c1"># use cv.glmnet to find best lambda/penalty 
# s is the penalty parameter
</span><span class="n">cv</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cv.glmnet</span><span class="p">(</span><span class="n">train_sparse</span><span class="p">,</span><span class="n">train</span><span class="p">[,</span><span class="m">11</span><span class="p">],</span><span class="n">nfolds</span><span class="o">=</span><span class="m">3</span><span class="p">)</span><span class="w">
</span><span class="n">pred</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="n">test_sparse</span><span class="p">,</span><span class="n">type</span><span class="o">=</span><span class="s2">"response"</span><span class="p">,</span><span class="w"> </span><span class="n">s</span><span class="o">=</span><span class="n">cv</span><span class="o">$</span><span class="n">lambda.min</span><span class="p">)</span><span class="w">

</span><span class="c1">#  receiver operating characteristic (ROC curves)
</span><span class="n">library</span><span class="p">(</span><span class="n">pROC</span><span class="p">)</span><span class="w">  
</span><span class="n">auc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">roc</span><span class="p">(</span><span class="n">test</span><span class="p">[,</span><span class="m">11</span><span class="p">],</span><span class="w"> </span><span class="n">pred</span><span class="p">)</span><span class="w">
</span><span class="n">print</span><span class="p">(</span><span class="n">auc</span><span class="o">$</span><span class="n">auc</span><span class="p">)</span><span class="w">

</span><span class="c1"># how does sparse deal with categorical data (adding mood feature with two levels)?
</span><span class="n">cat_dataframe</span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read.table</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s2">"c1     c2     c3     c4     c5     c6     c7     c8     c9     c10     mood     outcome
2     7     0     0     0     0     0     0     0     0     happy     0
0     0     3     0     0     0     0     0     0     0     happy     0
0     0     0     6     1     0     0     0     0     0     happy     0
0     0     0     2     0     0     0     0     0     0     happy     0
0     0     0     0     0     0     0     0     12     0     sad     1
0     0     0     0     0     25     0     0     0     0     sad     1
1     0     0     0     2     0     0     0     0     0     happy     0
0     0     0     2     0     0     0     0     0     0     happy     0
0     0     0     0     0     0     0     0     14     0     sad     1
0     0     0     0     0     21     0     0     0     0     sad     1
0     0     0     0     0     0     28     0     0     0     sad     1
0     0     0     0     0     0     0     35     0     0     sad     1
0     0     0     0     0     0     0     0     42     0     sad     1
0     0     0     0     0     0     0     0     0     49     sad     1"</span><span class="p">,</span><span class="w"> </span><span class="n">header</span><span class="o">=</span><span class="nb">T</span><span class="p">,</span><span class="w"> </span><span class="n">sep</span><span class="o">=</span><span class="s2">""</span><span class="p">)</span><span class="w"> 
</span><span class="n">print</span><span class="p">(</span><span class="n">sparse.model.matrix</span><span class="p">(</span><span class="o">~</span><span class="n">.</span><span class="p">,</span><span class="n">cat_dataframe</span><span class="p">))</span><span class="w">

</span><span class="c1"># increasing the number of levels in the mood variable)
</span><span class="n">cat_dataframe</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read.table</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s2">"c1     c2     c3     c4     c5     c6     c7     c8     c9     c10     mood     outcome
2     7     0     0     0     0     0     0     0     0     angry     0
0     0     3     0     0     0     0     0     0     0     neutral     0
0     0     0     6     1     0     0     0     0     0     happy     0
0     0     0     2     0     0     0     0     0     0     happy     0
0     0     0     0     0     0     0     0     12     0     sad     1
0     0     0     0     0     25     0     0     0     0     sad     1
1     0     0     0     2     0     0     0     0     0     happy     0
0     0     0     2     0     0     0     0     0     0     happy     0
0     0     0     0     0     0     0     0     14     0     sad     1
0     0     0     0     0     21     0     0     0     0     neutral     1
0     0     0     0     0     0     28     0     0     0     sad     1
0     0     0     0     0     0     0     35     0     0     sad     1
0     0     0     0     0     0     0     0     42     0     sad     1
0     0     0     0     0     0     0     0     0     49     sad     1"</span><span class="p">,</span><span class="w"> </span><span class="n">header</span><span class="o">=</span><span class="nb">T</span><span class="p">,</span><span class="w"> </span><span class="n">sep</span><span class="o">=</span><span class="s2">""</span><span class="p">)</span><span class="w"> 
</span><span class="n">print</span><span class="p">(</span><span class="n">levels</span><span class="p">(</span><span class="n">cat_dataframe</span><span class="o">$</span><span class="n">mood</span><span class="p">))</span><span class="w">
</span><span class="nf">dim</span><span class="p">(</span><span class="n">cat_dataframe</span><span class="p">)</span><span class="w">
</span><span class="c1"># sparse added extra columns when in binarized mood
</span><span class="nf">dim</span><span class="p">(</span><span class="n">sparse.model.matrix</span><span class="p">(</span><span class="o">~</span><span class="n">.</span><span class="p">,</span><span class="n">cat_dataframe</span><span class="p">))</span><span class="w">

</span></code></pre>
</div>
		
</div>
    
<p>Manuel Amunategui - Follow me on Twitter: @amunategui</p>
		</div>		 
	 </div>   
 
</main>
{% include mid_point_ad.html %}

{% include footer.html %}
  </body>
</html>
