---
---
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="Machine Learning, R Programming, Statistics, Artificial Intelligence">
    <meta name="author" content="Manuel Amunategui">
    <link rel="icon" href="../favicon.ico">

    <title>Data Exploration & Machine Learning, Hands-on</title>

    {% include externals.html %}
  
</head>

  

<body>

<main role="main">

{% include header.html %}
   
{% include signup.html %}

<div class="container">
  <div class="blog-header">
    <h1 class="blog-title">Anomaly Detection: Increasing Classification Accuracy with H2O's Autoencoder and R</h1>
    <p class="lead blog-description">Practical walkthroughs on machine learning, data exploration and finding insight.</p>
  </div>


<p style="text-align:center">
<img src="img/encoding_squeeze.png" alt="encoding_squeeze" style="padding:1px; border:1px solid #021a40; width: 30%; height: 30%" /></p>

<p><br /><br />
<strong>Resources</strong></p>
<ul>
<li type="square"><a href="https://www.youtube.com/watch?v=bRbrOQHpvNc&amp;index=1&amp;list=UUq4pm1i_VZqxKVVOz5qRBIA" target="_blank">YouTube Companion Video</a></li>
<li type="square"><a href="#sourcecode">Full Source Code</a></li>
</ul>
<p><br />
<strong>Packages Used in this Walkthrough</strong></p>
<ul>
<li type="square"><a href="https://cran.r-project.org/web/packages/h2o/index.html" target="_blank">{h2o}: R Interface for H2O</a></li>
<li type="square"><a href="https://cran.r-project.org/web/packages/randomForest/index.html" target="_blank">{randomForest}: Breiman and Cutler's Random Forests for Classification and Regression</a></li>
<li type="square"><a href="https://cran.r-project.org/web/packages/pROC/index.html" target="_blank">{pROC} - Display and Analyze ROC Curves</a></li>
</ul>
<p><br /><br /><br /></p>

<p><strong>Introduction</strong></p>
<ul>
<li type="square"><a href="#intro">Anomaly Detection</a></li>
<li type="square"><a href="#h2o">H2O on AWS</a></li>
<li type="square"><a href="#code">Let's code!</a></li>
<li type="square"><a href="#benchmark">Benchmark Random Forest Model</a></li>
<li type="square"><a href="#autoencoder">Autoencoder</a></li>
<li type="square"><a href="#anomaly">Modeling With and Without Anomalies</a></li>
</ul>

<p>Let’s apply <a href="http://www.h2o.ai/product/" target="_blank">H2O’s</a> anomaly detection to separate a data set into <strong>easy</strong> and <strong>hard</strong> to model subsets and attempt to gain predictive accuracy.</p>

<p>For those who don’t know yet, <code class="highlighter-rouge">H2O</code> is an open-source software for machine learning and big-data analysis. It offers various models such as <strong>GLM</strong>, <strong>GBM</strong> and <strong>Random Forest</strong>, but more importantly, offers a <strong>deep learning neural network</strong> and large-scale clustering!</p>

<p>For a great introduction to numerous features check out: <a href="https://h2o-release.s3.amazonaws.com/h2o/rel-slater/9/docs-website/h2o-docs/booklets/DeepLearning_Vignette.pdf" target="_blank">DeepLearning_Vignette.pdf</a>
<br /><br /></p>
<h3><a id="intro">Anomaly Detection</a></h3>

<blockquote><i>Anomaly detection (or outlier detection) is the identification of items, events or observations which do not conform to an expected pattern or other items in a dataset</i> - <a href="https://en.wikipedia.org/wiki/Anomaly_detection" target="_blank">Wikipedia.com</a></blockquote>

<p>Anomaly Detection is a big scientific domain, and with such big domains, come many associated techniques and tools. The <a href="https://en.wikipedia.org/wiki/Autoencoder" target="_blank">autoencoder</a> is one of those tools and the subject of this walk-through. <strong>H2O</strong> offers an easy to use, unsupervised and non-linear <code class="highlighter-rouge">autoencoder</code> as part of its <code class="highlighter-rouge">deeplearning</code> model. Autoencoding mostly aims at reducing feature space in order to distill the essential aspects of the data versus more conventional deeplearning which blows up the feature space up to capture non-linearities and subtle interactions within the data. Autoencoding can also be seen as a non-linear alternative to <a href="http://amunategui.github.io/high-demensions-pca/" target="_blank">PCA</a>.</p>

<p>Here is an interesting video from Arno Candel, the Chief Architect of H2O.ai, <a href="https://www.youtube.com/watch?v=fUSbljByXak" target="_blank">Anomaly Detection and Feature Engineering</a> using the <a href="https://en.wikipedia.org/wiki/MNIST_database" target="_blank">MINST<a></a> data set.</a></p>

<p><br /><br /></p>
<h3><a id="h2o">H2O on AWS</a></h3>
<p>I will use <strong>H2O</strong> on <a href="https://aws.amazon.com/" target="_blank">Amazon Web Services (AWS)</a> as it is both trivial to set up and advantageous to your research (H2O supports cluster computing for distributed tasks). In the video, I quickly set up a new H2O Amazon Web Service (AWS) instance but won’t cover it here as it is fully covered in my previous walk-through and video entitled <a href="http://amunategui.github.io/h2o-on-aws/" target="_blank">H2O &amp; RStudio Server on Amazon Web Services (AWS), the Easy Way!</a>.
<br /><br /></p>
<h3><a id="code">Let's code!</a></h3>

<p>First thing we need to do once we have RStudio up and running is to install <code class="highlighter-rouge">H2O</code>:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">install.packages</span><span class="p">(</span><span class="s2">"h2o"</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<p>In the output pane during the installation of H2O, you will see:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="c1">## prostate                                html
</span></code></pre>
</div>

<p>This is the data set we will use to run our models. Let’s go get it and assign it to <code class="highlighter-rouge">prostate_df</code>:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="c1"># point to the prostate data set in the h2o folder - no need to load h2o in memory yet
</span><span class="n">prosPath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">system.file</span><span class="p">(</span><span class="s2">"extdata"</span><span class="p">,</span><span class="w"> </span><span class="s2">"prostate.csv"</span><span class="p">,</span><span class="w"> </span><span class="n">package</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"h2o"</span><span class="p">)</span><span class="w">
</span><span class="n">prostate_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read.csv</span><span class="p">(</span><span class="n">prosPath</span><span class="p">)</span><span class="w">

</span><span class="c1"># We don't need the ID field
</span><span class="n">prostate_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">prostate_df</span><span class="p">[,</span><span class="m">-1</span><span class="p">]</span><span class="w">
</span><span class="n">summary</span><span class="p">(</span><span class="n">prostate_df</span><span class="p">)</span><span class="w">

</span></code></pre>
</div>
<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="c1">##     CAPSULE            AGE             RACE           DPROS      
##  Min.   :0.0000   Min.   :43.00   Min.   :0.000   Min.   :1.000  
##  1st Qu.:0.0000   1st Qu.:62.00   1st Qu.:1.000   1st Qu.:1.000  
##  Median :0.0000   Median :67.00   Median :1.000   Median :2.000  
##  Mean   :0.4026   Mean   :66.04   Mean   :1.087   Mean   :2.271  
##  3rd Qu.:1.0000   3rd Qu.:71.00   3rd Qu.:1.000   3rd Qu.:3.000  
##  Max.   :1.0000   Max.   :79.00   Max.   :2.000   Max.   :4.000  
##      DCAPS            PSA              VOL           GLEASON     
##  Min.   :1.000   Min.   :  0.30   Min.   : 0.00   Min.   :0.000  
##  1st Qu.:1.000   1st Qu.:  5.00   1st Qu.: 0.00   1st Qu.:6.000  
##  Median :1.000   Median :  8.75   Median :14.25   Median :6.000  
##  Mean   :1.108   Mean   : 15.41   Mean   :15.81   Mean   :6.384  
##  3rd Qu.:1.000   3rd Qu.: 17.12   3rd Qu.:26.45   3rd Qu.:7.000  
##  Max.   :2.000   Max.   :139.70   Max.   :97.60   Max.   :9.000
</span></code></pre>
</div>
<p><br /><br /></p>
<h3><a id="benchmark">Benchmark Random Forest Model</a></h3>
<p>Let’s start by running a simple <a href="https://en.wikipedia.org/wiki/Random_forest" target="_blank">random forest</a> model on the data by splitting it in two random portions (with a seed) - a training and a testing portion. This will give us a base score to measure our improvements using autoencoding.</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">set.seed</span><span class="p">(</span><span class="m">1234</span><span class="p">)</span><span class="w">
</span><span class="n">random_splits</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">runif</span><span class="p">(</span><span class="n">nrow</span><span class="p">(</span><span class="n">prostate_df</span><span class="p">))</span><span class="w">
</span><span class="n">train_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">prostate_df</span><span class="p">[</span><span class="n">random_splits</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">.5</span><span class="p">,]</span><span class="w">
</span><span class="nf">dim</span><span class="p">(</span><span class="n">train_df</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>
<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="c1">## [1] 193   8
</span></code></pre>
</div>
<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">validate_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">prostate_df</span><span class="p">[</span><span class="n">random_splits</span><span class="w"> </span><span class="o">&gt;=</span><span class="m">.5</span><span class="p">,]</span><span class="w">
</span><span class="nf">dim</span><span class="p">(</span><span class="n">validate_df</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>
<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="c1">## [1] 187   8
</span></code></pre>
</div>
<p><br /><br />
Install packages <strong>randomForest</strong> and <strong>pROC</strong> and run a simple classification model on outcome variable <code class="highlighter-rouge">CAPSULE</code>:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">install.packages</span><span class="p">(</span><span class="s1">'randomForest'</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">randomForest</span><span class="p">)</span><span class="w">

</span><span class="n">outcome_name</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s1">'CAPSULE'</span><span class="w">
</span><span class="n">feature_names</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">setdiff</span><span class="p">(</span><span class="nf">names</span><span class="p">(</span><span class="n">prostate_df</span><span class="p">),</span><span class="w"> </span><span class="n">outcome_name</span><span class="p">)</span><span class="w">
</span><span class="n">set.seed</span><span class="p">(</span><span class="m">1234</span><span class="p">)</span><span class="w">
</span><span class="n">rf_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">randomForest</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">train_df</span><span class="p">[,</span><span class="n">feature_names</span><span class="p">],</span><span class="w">
                         </span><span class="n">y</span><span class="o">=</span><span class="n">as.factor</span><span class="p">(</span><span class="n">train_df</span><span class="p">[,</span><span class="n">outcome_name</span><span class="p">]),</span><span class="w">
                         </span><span class="n">importance</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">ntree</span><span class="o">=</span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">mtry</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">)</span><span class="w">

</span><span class="n">validate_predictions</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">rf_model</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="o">=</span><span class="n">validate_df</span><span class="p">[,</span><span class="n">feature_names</span><span class="p">],</span><span class="w"> </span><span class="n">type</span><span class="o">=</span><span class="s2">"prob"</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>
<p><br /><br />
Let’s use the <code class="highlighter-rouge">pROC</code> library to calculate our AUC score (remember, an AUC of 0.5 is random and 1 is perfect) and plot a chart:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">install.packages</span><span class="p">(</span><span class="s1">'pROC'</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">pROC</span><span class="p">)</span><span class="w">
</span><span class="n">auc_rf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">roc</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="nf">as.numeric</span><span class="p">(</span><span class="n">as.factor</span><span class="p">(</span><span class="n">validate_df</span><span class="p">[,</span><span class="n">outcome_name</span><span class="p">]))</span><span class="m">-1</span><span class="p">,</span><span class="w">
             </span><span class="n">predictor</span><span class="o">=</span><span class="n">validate_predictions</span><span class="p">[,</span><span class="m">2</span><span class="p">])</span><span class="w">

</span><span class="n">plot</span><span class="p">(</span><span class="n">auc_rf</span><span class="p">,</span><span class="w"> </span><span class="n">print.thres</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"best"</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="n">paste</span><span class="p">(</span><span class="s1">'AUC:'</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="n">auc_rf</span><span class="o">$</span><span class="n">auc</span><span class="p">[[</span><span class="m">1</span><span class="p">]],</span><span class="m">3</span><span class="p">)))</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">h</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="n">col</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">h</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">col</span><span class="o">=</span><span class="s1">'green'</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>
<p><br /><br /></p>
<p style="text-align:center">
<img src="img/auc_0.757_intro.png" alt="AUC Chart" style="padding:1px; border:1px solid #021a40; width: 50%; height: 50%" /></p>

<p>We get an AUC of <strong>0.757</strong> with our current data split.
<br /><br /></p>
<h3><a id="autoencoder">Autoencoder</a></h3>
<p>Let’s see how an unsupervised <strong>autoencoding</strong> can assist us here. Start by initializing an h2o instance and create an H2O frame from the prostate data set:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">h</span><span class="m">2</span><span class="n">o</span><span class="p">)</span><span class="w">
</span><span class="n">localH2O</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">h</span><span class="m">2</span><span class="n">o.init</span><span class="p">()</span><span class="w">

</span><span class="n">prostate.hex</span><span class="o">&lt;-</span><span class="n">as.h2o</span><span class="p">(</span><span class="n">train_df</span><span class="p">,</span><span class="w"> </span><span class="n">destination_frame</span><span class="o">=</span><span class="s2">"train.hex"</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>
<p><br /><br />
Getting down to the heart of our business, let’s call the deeplearning function with parameter <code class="highlighter-rouge">autoencoder</code> set to TRUE (we also set the <code class="highlighter-rouge">reproducible</code> flag to <code class="highlighter-rouge">TRUE</code> along with a seed so we all see the same results but this is substantially slower than setting the flag to <code class="highlighter-rouge">FALSE</code>):</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">prostate.dl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">h</span><span class="m">2</span><span class="n">o.deeplearning</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">feature_names</span><span class="p">,</span><span class="w"> </span><span class="n">training_frame</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prostate.hex</span><span class="p">,</span><span class="w">
                               </span><span class="n">autoencoder</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w">
                               </span><span class="n">reproducible</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">T</span><span class="p">,</span><span class="w">
                               </span><span class="n">seed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1234</span><span class="p">,</span><span class="w">
                               </span><span class="n">hidden</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">6</span><span class="p">,</span><span class="m">5</span><span class="p">,</span><span class="m">6</span><span class="p">),</span><span class="w"> </span><span class="n">epochs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">50</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>
<p><br /><br />
We now call the <a href="http://rpackages.ianhowson.com/cran/h2o/man/h2o.anomaly.html" target="_blank">h2o.anomaly</a> function to reconstruct the original data set using the reduced set of features and calculate a means squared error between both. Here we set <code class="highlighter-rouge">per_feature</code> parameter to FALSE in the <code class="highlighter-rouge">h2o.anomaly</code> function call as we want a reconstruction meany error based on observations, not individual features (but you should definitely play around feature-level scores as it could lead to important insights into your data).</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="c1"># prostate.anon = h2o.anomaly(prostate.dl, prostate.hex, per_feature=TRUE)
# head(prostate.anon)
</span><span class="w">
</span><span class="n">prostate.anon</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">h</span><span class="m">2</span><span class="n">o.anomaly</span><span class="p">(</span><span class="n">prostate.dl</span><span class="p">,</span><span class="w"> </span><span class="n">prostate.hex</span><span class="p">,</span><span class="w"> </span><span class="n">per_feature</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span><span class="n">head</span><span class="p">(</span><span class="n">prostate.anon</span><span class="p">)</span><span class="w">
</span><span class="n">err</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.data.frame</span><span class="p">(</span><span class="n">prostate.anon</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>
<p><br /><br />
Let’s sort and plot the reconstructed MSE. The autoencoder struggles from index 150 onwards as the error count accelerates upwards. We can determine that the model recognizes patterns in the first 150 observations that it can’t see as easily in the last 50.</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">plot</span><span class="p">(</span><span class="n">sort</span><span class="p">(</span><span class="n">err</span><span class="o">$</span><span class="n">Reconstruction.MSE</span><span class="p">),</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s1">'Reconstruction Error'</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>
<p><br /><br /></p>
<p style="text-align:center">
<img src="img/err_plot.png" alt="Error Chart" style="padding:1px; border:1px solid #021a40; width: 50%; height: 50%" /></p>
<p><br /><br /></p>
<h3><a id="anomaly">Modeling With and Without Anomalies</a></h3>
<p>The next logical step is to use the clean observations, those that the autoencoder reconstructed easily and model that with our random forest model. We use the <code class="highlighter-rouge">err</code>’s <code class="highlighter-rouge">Reconstruction.MSE</code> vector to gather everything all observations in our prostate data set with an error below 0.1:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="c1"># rebuild train_df_auto with best observations
</span><span class="n">train_df_auto</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">train_df</span><span class="p">[</span><span class="n">err</span><span class="o">$</span><span class="n">Reconstruction.MSE</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">0.1</span><span class="p">,]</span><span class="w">

</span><span class="n">set.seed</span><span class="p">(</span><span class="m">1234</span><span class="p">)</span><span class="w">
</span><span class="n">rf_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">randomForest</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">train_df_auto</span><span class="p">[,</span><span class="n">feature_names</span><span class="p">],</span><span class="w">
                         </span><span class="n">y</span><span class="o">=</span><span class="n">as.factor</span><span class="p">(</span><span class="n">train_df_auto</span><span class="p">[,</span><span class="n">outcome_name</span><span class="p">]),</span><span class="w">
                         </span><span class="n">importance</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">ntree</span><span class="o">=</span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">mtry</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">)</span><span class="w">

</span><span class="n">validate_predictions_known</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">rf_model</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="o">=</span><span class="n">validate_df</span><span class="p">[,</span><span class="n">feature_names</span><span class="p">],</span><span class="w"> </span><span class="n">type</span><span class="o">=</span><span class="s2">"prob"</span><span class="p">)</span><span class="w">

</span><span class="n">auc_rf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">roc</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="nf">as.numeric</span><span class="p">(</span><span class="n">as.factor</span><span class="p">(</span><span class="n">validate_df</span><span class="p">[,</span><span class="n">outcome_name</span><span class="p">]))</span><span class="m">-1</span><span class="p">,</span><span class="w">
             </span><span class="n">predictor</span><span class="o">=</span><span class="n">validate_predictions_known</span><span class="p">[,</span><span class="m">2</span><span class="p">])</span><span class="w">

</span><span class="n">plot</span><span class="p">(</span><span class="n">auc_rf</span><span class="p">,</span><span class="w"> </span><span class="n">print.thres</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"best"</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="n">paste</span><span class="p">(</span><span class="s1">'AUC:'</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="n">auc_rf</span><span class="o">$</span><span class="n">auc</span><span class="p">[[</span><span class="m">1</span><span class="p">]],</span><span class="m">3</span><span class="p">)))</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">h</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="n">col</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">h</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">col</span><span class="o">=</span><span class="s1">'green'</span><span class="p">)</span><span class="w">

</span></code></pre>
</div>
<p><br /><br /></p>
<p style="text-align:center">
<img src="img/auc_0.78_easy.png" alt="AUC Chart" style="padding:1px; border:1px solid #021a40; width: 50%; height: 50%" /></p>
<p><br />
An AUC of 0.78, an improvement over our original random forest model of 0.757 while using less observations!</p>

<p>Let’s try the same model on the hard to reconstruct portion:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="c1"># rebuild train_df_auto with best observations
</span><span class="n">train_df_auto</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">train_df</span><span class="p">[</span><span class="n">err</span><span class="o">$</span><span class="n">Reconstruction.MSE</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="m">0.1</span><span class="p">,]</span><span class="w">

</span><span class="n">set.seed</span><span class="p">(</span><span class="m">1234</span><span class="p">)</span><span class="w">
</span><span class="n">rf_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">randomForest</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">train_df_auto</span><span class="p">[,</span><span class="n">feature_names</span><span class="p">],</span><span class="w">
                         </span><span class="n">y</span><span class="o">=</span><span class="n">as.factor</span><span class="p">(</span><span class="n">train_df_auto</span><span class="p">[,</span><span class="n">outcome_name</span><span class="p">]),</span><span class="w">
                         </span><span class="n">importance</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">ntree</span><span class="o">=</span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">mtry</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">)</span><span class="w">

</span><span class="n">validate_predictions_unknown</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">rf_model</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="o">=</span><span class="n">validate_df</span><span class="p">[,</span><span class="n">feature_names</span><span class="p">],</span><span class="w"> </span><span class="n">type</span><span class="o">=</span><span class="s2">"prob"</span><span class="p">)</span><span class="w">

</span><span class="n">auc_rf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">roc</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="nf">as.numeric</span><span class="p">(</span><span class="n">as.factor</span><span class="p">(</span><span class="n">validate_df</span><span class="p">[,</span><span class="n">outcome_name</span><span class="p">]))</span><span class="m">-1</span><span class="p">,</span><span class="w">
             </span><span class="n">predictor</span><span class="o">=</span><span class="n">validate_predictions_unknown</span><span class="p">[,</span><span class="m">2</span><span class="p">])</span><span class="w">

</span><span class="n">plot</span><span class="p">(</span><span class="n">auc_rf</span><span class="p">,</span><span class="w"> </span><span class="n">print.thres</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"best"</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="n">paste</span><span class="p">(</span><span class="s1">'AUC:'</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="n">auc_rf</span><span class="o">$</span><span class="n">auc</span><span class="p">[[</span><span class="m">1</span><span class="p">]],</span><span class="m">3</span><span class="p">)))</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">h</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="n">col</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">h</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">col</span><span class="o">=</span><span class="s1">'green'</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>
<p><br /><br /></p>
<p style="text-align:center">
<img src="img/auc_0.752_hard.png" alt="AUC Chart" style="padding:1px; border:1px solid #021a40; width: 50%; height: 50%" /></p>
<p><br /><br />
It should be clear by now that these top portions behave very differently under the same model. What about bagging both prediction sets (adding both prediction vectors together and dividing the total by two)?</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">valid_all</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="p">(</span><span class="n">validate_predictions_known</span><span class="p">[,</span><span class="m">2</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">validate_predictions_unknown</span><span class="p">[,</span><span class="m">2</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="m">2</span><span class="w">

</span><span class="n">auc_rf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">roc</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="nf">as.numeric</span><span class="p">(</span><span class="n">as.factor</span><span class="p">(</span><span class="n">validate_df</span><span class="p">[,</span><span class="n">outcome_name</span><span class="p">]))</span><span class="m">-1</span><span class="p">,</span><span class="w">
             </span><span class="n">predictor</span><span class="o">=</span><span class="n">valid_all</span><span class="p">)</span><span class="w">

</span><span class="n">plot</span><span class="p">(</span><span class="n">auc_rf</span><span class="p">,</span><span class="w"> </span><span class="n">print.thres</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"best"</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="n">paste</span><span class="p">(</span><span class="s1">'AUC:'</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="n">auc_rf</span><span class="o">$</span><span class="n">auc</span><span class="p">[[</span><span class="m">1</span><span class="p">]],</span><span class="m">3</span><span class="p">)))</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">h</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="n">col</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">h</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">col</span><span class="o">=</span><span class="s1">'green'</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>
<p><br /><br /></p>
<p style="text-align:center">
<img src="img/auc_0.816_final.png" alt="AUC Chart" style="padding:1px; border:1px solid #021a40; width: 50%; height: 50%" /></p>
<p><br /></p>

<p>Tremendous! We end up with an AUC of 0.816!! Awesome! In this case, random forest benefitted from the splitting of our data set into two groups of varying patterns. In essence it managed to create better trees for each type which it couldn’t do with the larger original set. Mind you, this doesn’t always pan out this way - a lot has to do on the type of data you are dealing with and the modeling algorithms.</p>

<p><b>Note:</b> H2O is a fast moving development project, so if certain aspects of this walk-through don’t work, check the documentation for changes in the library.
<br /><br />     <br />
<i>A special thanks to Lucas A. for the autoencoding fist artwork!</i>
<br />
<br /><br />      <br />

{% include share-the-love.html %}

<a id="sourcecode">Full source code</a>:
<br /><br /></p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="w">
</span><span class="c1"># install.packages("h2o")
</span><span class="w">
</span><span class="c1"># point to the prostate data set in the h2o folder - no need to load h2o in memory yet
</span><span class="n">prosPath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">system.file</span><span class="p">(</span><span class="s2">"extdata"</span><span class="p">,</span><span class="w"> </span><span class="s2">"prostate.csv"</span><span class="p">,</span><span class="w"> </span><span class="n">package</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"h2o"</span><span class="p">)</span><span class="w">
</span><span class="n">prostate_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read.csv</span><span class="p">(</span><span class="n">prosPath</span><span class="p">)</span><span class="w">

</span><span class="c1"># We don't need the ID field
</span><span class="n">prostate_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">prostate_df</span><span class="p">[,</span><span class="m">-1</span><span class="p">]</span><span class="w">
</span><span class="n">summary</span><span class="p">(</span><span class="n">prostate_df</span><span class="p">)</span><span class="w">

</span><span class="n">set.seed</span><span class="p">(</span><span class="m">1234</span><span class="p">)</span><span class="w">
</span><span class="n">random_splits</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">runif</span><span class="p">(</span><span class="n">nrow</span><span class="p">(</span><span class="n">prostate_df</span><span class="p">))</span><span class="w">
</span><span class="n">train_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">prostate_df</span><span class="p">[</span><span class="n">random_splits</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">.5</span><span class="p">,]</span><span class="w">
</span><span class="nf">dim</span><span class="p">(</span><span class="n">train_df</span><span class="p">)</span><span class="w">

</span><span class="n">validate_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">prostate_df</span><span class="p">[</span><span class="n">random_splits</span><span class="w"> </span><span class="o">&gt;=</span><span class="m">.5</span><span class="p">,]</span><span class="w">
</span><span class="nf">dim</span><span class="p">(</span><span class="n">validate_df</span><span class="p">)</span><span class="w">

</span><span class="c1"># Get benchmark score
</span><span class="w">
</span><span class="c1"># install.packages('randomForest')
</span><span class="n">library</span><span class="p">(</span><span class="n">randomForest</span><span class="p">)</span><span class="w">

</span><span class="n">outcome_name</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s1">'CAPSULE'</span><span class="w">
</span><span class="n">feature_names</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">setdiff</span><span class="p">(</span><span class="nf">names</span><span class="p">(</span><span class="n">prostate_df</span><span class="p">),</span><span class="w"> </span><span class="n">outcome_name</span><span class="p">)</span><span class="w">
</span><span class="n">set.seed</span><span class="p">(</span><span class="m">1234</span><span class="p">)</span><span class="w">
</span><span class="n">rf_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">randomForest</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">train_df</span><span class="p">[,</span><span class="n">feature_names</span><span class="p">],</span><span class="w">
                         </span><span class="n">y</span><span class="o">=</span><span class="n">as.factor</span><span class="p">(</span><span class="n">train_df</span><span class="p">[,</span><span class="n">outcome_name</span><span class="p">]),</span><span class="w">
                         </span><span class="n">importance</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">ntree</span><span class="o">=</span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">mtry</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">)</span><span class="w">

</span><span class="n">validate_predictions</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">rf_model</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="o">=</span><span class="n">validate_df</span><span class="p">[,</span><span class="n">feature_names</span><span class="p">],</span><span class="w"> </span><span class="n">type</span><span class="o">=</span><span class="s2">"prob"</span><span class="p">)</span><span class="w">


</span><span class="c1"># install.packages('pROC')
</span><span class="n">library</span><span class="p">(</span><span class="n">pROC</span><span class="p">)</span><span class="w">
</span><span class="n">auc_rf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">roc</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="nf">as.numeric</span><span class="p">(</span><span class="n">as.factor</span><span class="p">(</span><span class="n">validate_df</span><span class="p">[,</span><span class="n">outcome_name</span><span class="p">]))</span><span class="m">-1</span><span class="p">,</span><span class="w">
             </span><span class="n">predictor</span><span class="o">=</span><span class="n">validate_predictions</span><span class="p">[,</span><span class="m">2</span><span class="p">])</span><span class="w">

</span><span class="n">plot</span><span class="p">(</span><span class="n">auc_rf</span><span class="p">,</span><span class="w"> </span><span class="n">print.thres</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"best"</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="n">paste</span><span class="p">(</span><span class="s1">'AUC:'</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="n">auc_rf</span><span class="o">$</span><span class="n">auc</span><span class="p">[[</span><span class="m">1</span><span class="p">]],</span><span class="m">3</span><span class="p">)))</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">h</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="n">col</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">h</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">col</span><span class="o">=</span><span class="s1">'green'</span><span class="p">)</span><span class="w">

</span><span class="c1"># build autoencoder model
</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">h</span><span class="m">2</span><span class="n">o</span><span class="p">)</span><span class="w">
</span><span class="n">localH2O</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">h</span><span class="m">2</span><span class="n">o.init</span><span class="p">()</span><span class="w">
</span><span class="n">prostate.hex</span><span class="o">&lt;-</span><span class="n">as.h2o</span><span class="p">(</span><span class="n">train_df</span><span class="p">,</span><span class="w"> </span><span class="n">destination_frame</span><span class="o">=</span><span class="s2">"train.hex"</span><span class="p">)</span><span class="w">
</span><span class="n">prostate.dl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">h</span><span class="m">2</span><span class="n">o.deeplearning</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">feature_names</span><span class="p">,</span><span class="w"> </span><span class="n">training_frame</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prostate.hex</span><span class="p">,</span><span class="w">
                               </span><span class="n">autoencoder</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w">
                               </span><span class="n">reproducible</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">T</span><span class="p">,</span><span class="w">
                               </span><span class="n">seed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1234</span><span class="p">,</span><span class="w">
                               </span><span class="n">hidden</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">6</span><span class="p">,</span><span class="m">5</span><span class="p">,</span><span class="m">6</span><span class="p">),</span><span class="w"> </span><span class="n">epochs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">50</span><span class="p">)</span><span class="w">

</span><span class="c1"># interesting per feature error scores
# prostate.anon = h2o.anomaly(prostate.dl, prostate.hex, per_feature=TRUE)
# head(prostate.anon)
</span><span class="w">
</span><span class="n">prostate.anon</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">h</span><span class="m">2</span><span class="n">o.anomaly</span><span class="p">(</span><span class="n">prostate.dl</span><span class="p">,</span><span class="w"> </span><span class="n">prostate.hex</span><span class="p">,</span><span class="w"> </span><span class="n">per_feature</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span><span class="n">head</span><span class="p">(</span><span class="n">prostate.anon</span><span class="p">)</span><span class="w">
</span><span class="n">err</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.data.frame</span><span class="p">(</span><span class="n">prostate.anon</span><span class="p">)</span><span class="w">

</span><span class="c1"># interesting reduced features (defaults to last hidden layer)
# http://www.rdocumentation.org/packages/h2o/functions/h2o.deepfeatures
# reduced_new  &lt;- h2o.deepfeatures(prostate.dl, prostate.hex)
</span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">sort</span><span class="p">(</span><span class="n">err</span><span class="o">$</span><span class="n">Reconstruction.MSE</span><span class="p">))</span><span class="w">

</span><span class="c1"># use the easy portion and model with random forest using same settings
</span><span class="w">
</span><span class="n">train_df_auto</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">train_df</span><span class="p">[</span><span class="n">err</span><span class="o">$</span><span class="n">Reconstruction.MSE</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">0.1</span><span class="p">,]</span><span class="w">

</span><span class="n">set.seed</span><span class="p">(</span><span class="m">1234</span><span class="p">)</span><span class="w">
</span><span class="n">rf_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">randomForest</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">train_df_auto</span><span class="p">[,</span><span class="n">feature_names</span><span class="p">],</span><span class="w">
                         </span><span class="n">y</span><span class="o">=</span><span class="n">as.factor</span><span class="p">(</span><span class="n">train_df_auto</span><span class="p">[,</span><span class="n">outcome_name</span><span class="p">]),</span><span class="w">
                         </span><span class="n">importance</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">ntree</span><span class="o">=</span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">mtry</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">)</span><span class="w">

</span><span class="n">validate_predictions_known</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">rf_model</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="o">=</span><span class="n">validate_df</span><span class="p">[,</span><span class="n">feature_names</span><span class="p">],</span><span class="w"> </span><span class="n">type</span><span class="o">=</span><span class="s2">"prob"</span><span class="p">)</span><span class="w">

</span><span class="n">auc_rf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">roc</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="nf">as.numeric</span><span class="p">(</span><span class="n">as.factor</span><span class="p">(</span><span class="n">validate_df</span><span class="p">[,</span><span class="n">outcome_name</span><span class="p">]))</span><span class="m">-1</span><span class="p">,</span><span class="w">
             </span><span class="n">predictor</span><span class="o">=</span><span class="n">validate_predictions_known</span><span class="p">[,</span><span class="m">2</span><span class="p">])</span><span class="w">

</span><span class="n">plot</span><span class="p">(</span><span class="n">auc_rf</span><span class="p">,</span><span class="w"> </span><span class="n">print.thres</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"best"</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="n">paste</span><span class="p">(</span><span class="s1">'AUC:'</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="n">auc_rf</span><span class="o">$</span><span class="n">auc</span><span class="p">[[</span><span class="m">1</span><span class="p">]],</span><span class="m">3</span><span class="p">)))</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">h</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="n">col</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">h</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">col</span><span class="o">=</span><span class="s1">'green'</span><span class="p">)</span><span class="w">

</span><span class="c1"># use the hard portion and model with random forest using same settings
</span><span class="n">train_df_auto</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">train_df</span><span class="p">[</span><span class="n">err</span><span class="o">$</span><span class="n">Reconstruction.MSE</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="m">0.1</span><span class="p">,]</span><span class="w">

</span><span class="n">set.seed</span><span class="p">(</span><span class="m">1234</span><span class="p">)</span><span class="w">
</span><span class="n">rf_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">randomForest</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">train_df_auto</span><span class="p">[,</span><span class="n">feature_names</span><span class="p">],</span><span class="w">
                         </span><span class="n">y</span><span class="o">=</span><span class="n">as.factor</span><span class="p">(</span><span class="n">train_df_auto</span><span class="p">[,</span><span class="n">outcome_name</span><span class="p">]),</span><span class="w">
                         </span><span class="n">importance</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">ntree</span><span class="o">=</span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">mtry</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">)</span><span class="w">

</span><span class="n">validate_predictions_unknown</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">rf_model</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="o">=</span><span class="n">validate_df</span><span class="p">[,</span><span class="n">feature_names</span><span class="p">],</span><span class="w"> </span><span class="n">type</span><span class="o">=</span><span class="s2">"prob"</span><span class="p">)</span><span class="w">
</span><span class="n">auc_rf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">roc</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="nf">as.numeric</span><span class="p">(</span><span class="n">as.factor</span><span class="p">(</span><span class="n">validate_df</span><span class="p">[,</span><span class="n">outcome_name</span><span class="p">]))</span><span class="m">-1</span><span class="p">,</span><span class="w">
             </span><span class="n">predictor</span><span class="o">=</span><span class="n">validate_predictions_unknown</span><span class="p">[,</span><span class="m">2</span><span class="p">])</span><span class="w">

</span><span class="n">plot</span><span class="p">(</span><span class="n">auc_rf</span><span class="p">,</span><span class="w"> </span><span class="n">print.thres</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"best"</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="n">paste</span><span class="p">(</span><span class="s1">'AUC:'</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="n">auc_rf</span><span class="o">$</span><span class="n">auc</span><span class="p">[[</span><span class="m">1</span><span class="p">]],</span><span class="m">3</span><span class="p">)))</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">h</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="n">col</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">h</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">col</span><span class="o">=</span><span class="s1">'green'</span><span class="p">)</span><span class="w">

</span><span class="c1"># bag both results set and measure final AUC score
</span><span class="n">valid_all</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="p">(</span><span class="n">validate_predictions_known</span><span class="p">[,</span><span class="m">2</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">validate_predictions_unknown</span><span class="p">[,</span><span class="m">2</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="m">2</span><span class="w">
</span><span class="n">auc_rf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">roc</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="nf">as.numeric</span><span class="p">(</span><span class="n">as.factor</span><span class="p">(</span><span class="n">validate_df</span><span class="p">[,</span><span class="n">outcome_name</span><span class="p">]))</span><span class="m">-1</span><span class="p">,</span><span class="w">
             </span><span class="n">predictor</span><span class="o">=</span><span class="n">valid_all</span><span class="p">)</span><span class="w">

</span><span class="n">plot</span><span class="p">(</span><span class="n">auc_rf</span><span class="p">,</span><span class="w"> </span><span class="n">print.thres</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"best"</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="n">paste</span><span class="p">(</span><span class="s1">'AUC:'</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="n">auc_rf</span><span class="o">$</span><span class="n">auc</span><span class="p">[[</span><span class="m">1</span><span class="p">]],</span><span class="m">3</span><span class="p">)))</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">h</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="n">col</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">h</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">col</span><span class="o">=</span><span class="s1">'green'</span><span class="p">)</span><span class="w">






</span></code></pre>
</div>
		
</div>
    

		</div>		 
	 </div>   

</main>
{% include mid_point_ad.html %}

{% include footer.html %}
  </body>
</html>
